{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Tensorflow_basic and tf.layers / estimator api ",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "[View in Colaboratory](https://colab.research.google.com/github/sungreong/TIL/blob/master/Tensorflow_basic_and_tf_layers_estimator_api.ipynb)"
      ]
    },
    {
      "metadata": {
        "id": "ToJtVXIgDu99",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 161
        },
        "outputId": "70a20eee-4da8-485e-952b-df29ab5ce4d6"
      },
      "cell_type": "code",
      "source": [
        "from __future__ import division, print_function, absolute_import\n",
        "\n",
        "import tensorflow as tf\n",
        "\n",
        "# Import MNIST data\n",
        "from tensorflow.examples.tutorials.mnist import input_data\n",
        "mnist = input_data.read_data_sets(\"/tmp/data/\", one_hot=True)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Successfully downloaded train-images-idx3-ubyte.gz 9912422 bytes.\n",
            "Extracting /tmp/data/train-images-idx3-ubyte.gz\n",
            "Successfully downloaded train-labels-idx1-ubyte.gz 28881 bytes.\n",
            "Extracting /tmp/data/train-labels-idx1-ubyte.gz\n",
            "Successfully downloaded t10k-images-idx3-ubyte.gz 1648877 bytes.\n",
            "Extracting /tmp/data/t10k-images-idx3-ubyte.gz\n",
            "Successfully downloaded t10k-labels-idx1-ubyte.gz 4542 bytes.\n",
            "Extracting /tmp/data/t10k-labels-idx1-ubyte.gz\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "A7FsdvMjDvBJ",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "learning_rate = 0.001\n",
        "num_steps = 1000\n",
        "batch_size = 128\n",
        "display_step= 10 \n",
        "\n",
        "num_input = 784\n",
        "num_classes = 10 \n",
        "dropout = 0.75\n",
        "\n",
        "X = tf.placeholder( tf.float32 , [ None , num_input ])\n",
        "Y = tf.placeholder( tf.float32 , [ None , num_classes ])\n",
        "\n",
        "keep_prob = tf.placeholder( tf.float32 )"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "lYk2TaH3DvEK",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "def conv2d( x , W , b ,strides = 1 ) : \n",
        "    x = tf.nn.conv2d( x , W , strides = [ 1, strides , strides , 1], padding =\"SAME\")\n",
        "    x = tf.nn.bias_add(x, b )\n",
        "    return tf.nn.relu(x)\n",
        "\n",
        "def maxpool2d( x , k = 2 ) :\n",
        "    return tf.nn.max_pool( x, ksize  = [ 1, k , k , 1] , strides = [1, k , k , 1 ] ,\n",
        "                         padding =\"SAME\")\n",
        "\n",
        "def conv_net(x, weights, biases, dropout):\n",
        "    # MNIST data input is a 1-D vector of 784 features (28*28 pixels)\n",
        "    # Reshape to match picture format [Height x Width x Channel]\n",
        "    # Tensor input become 4-D: [Batch Size, Height, Width, Channel]\n",
        "    x = tf.reshape(x, shape=[-1, 28, 28, 1])\n",
        "\n",
        "    # Convolution Layer\n",
        "    conv1 = conv2d(x, weights['wc1'], biases['bc1'])\n",
        "    # Max Pooling (down-sampling)\n",
        "    conv1 = maxpool2d(conv1, k=2)\n",
        "\n",
        "    # Convolution Layer\n",
        "    conv2 = conv2d(conv1, weights['wc2'], biases['bc2'])\n",
        "    # Max Pooling (down-sampling)\n",
        "    conv2 = maxpool2d(conv2, k=2)\n",
        "\n",
        "    # Fully connected layer\n",
        "    # Reshape conv2 output to fit fully connected layer input\n",
        "    fc1 = tf.reshape(conv2, [-1, weights['wd1'].get_shape().as_list()[0]])\n",
        "    fc1 = tf.add(tf.matmul(fc1, weights['wd1']), biases['bd1'])\n",
        "    fc1 = tf.nn.relu(fc1)\n",
        "    # Apply Dropout\n",
        "    fc1 = tf.nn.dropout(fc1, dropout)\n",
        "\n",
        "    # Output, class prediction\n",
        "    out = tf.add(tf.matmul(fc1, weights['out']), biases['out'])\n",
        "    return out"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "DeIYZsIVDvHC",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "weights = {\n",
        "    # 5x5 conv, 1 input, 32 outputs\n",
        "    'wc1': tf.Variable(tf.random_normal([5, 5, 1, 32])),\n",
        "    # 5x5 conv, 32 inputs, 64 outputs\n",
        "    'wc2': tf.Variable(tf.random_normal([5, 5, 32, 64])),\n",
        "    # fully connected, 7*7*64 inputs, 1024 outputs\n",
        "    'wd1': tf.Variable(tf.random_normal([7*7*64, 1024])),\n",
        "    # 1024 inputs, 10 outputs (class prediction)\n",
        "    'out': tf.Variable(tf.random_normal([1024, num_classes]))\n",
        "}\n",
        "\n",
        "biases = {\n",
        "    'bc1': tf.Variable(tf.random_normal([32])),\n",
        "    'bc2': tf.Variable(tf.random_normal([64])),\n",
        "    'bd1': tf.Variable(tf.random_normal([1024])),\n",
        "    'out': tf.Variable(tf.random_normal([num_classes]))\n",
        "}\n",
        "\n",
        "\n",
        "logits = conv_net( X , weights , biases , keep_prob )\n",
        "prediction = tf.nn.softmax(logits)\n",
        "\n",
        "loss_op = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits(\n",
        "    logits=logits, labels=Y))\n",
        "optimizer = tf.train.AdamOptimizer(learning_rate=learning_rate)\n",
        "train_op = optimizer.minimize(loss_op)\n",
        "\n",
        "\n",
        "# 평가 모델 \n",
        "correct_pred = tf.equal(tf.argmax(prediction, 1), tf.argmax(Y, 1))\n",
        "accuracy = tf.reduce_mean(tf.cast(correct_pred, tf.float32))\n",
        "\n",
        "# Initialize the variables \n",
        "init = tf.global_variables_initializer()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "Nu6AfDUxDvKD",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1871
        },
        "outputId": "c1695016-5a5b-44b3-991c-ab08ce799708"
      },
      "cell_type": "code",
      "source": [
        "\n",
        "with tf.Session() as sess:\n",
        "\n",
        "    # Run the initializer\n",
        "    sess.run(init)\n",
        "\n",
        "    for step in range(1, num_steps+1):\n",
        "        batch_x, batch_y = mnist.train.next_batch(batch_size)\n",
        "        # Run optimization op (backprop)\n",
        "        sess.run(train_op, feed_dict={X: batch_x, Y: batch_y, keep_prob: dropout})\n",
        "        if step % display_step == 0 or step == 1:\n",
        "            # Calculate batch loss and accuracy\n",
        "            loss, acc = sess.run([loss_op, accuracy], feed_dict={X: batch_x,\n",
        "                                                                 Y: batch_y,\n",
        "                                                                 keep_prob: 1.0})\n",
        "            print(\"Step \" + str(step) + \", batch Loss= \" + \\\n",
        "                  \"{:.4f}\".format(loss) + \", Training Accuracy= \" + \\\n",
        "                  \"{:.3f}\".format(acc))\n",
        "\n",
        "    print(\"최적화 완료\")\n",
        "\n",
        "    # Calculate accuracy for 256 MNIST test images\n",
        "    print(\"Testing Accuracy:\", \\\n",
        "        sess.run(accuracy, feed_dict={X: mnist.test.images[:256],\n",
        "                                      Y: mnist.test.labels[:256],\n",
        "                                      keep_prob: 1.0}))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Step 1, batch Loss= 92664.6719, Training Accuracy= 0.070\n",
            "Step 10, batch Loss= 27938.1289, Training Accuracy= 0.234\n",
            "Step 20, batch Loss= 13057.3467, Training Accuracy= 0.438\n",
            "Step 30, batch Loss= 4391.1191, Training Accuracy= 0.648\n",
            "Step 40, batch Loss= 5976.3457, Training Accuracy= 0.719\n",
            "Step 50, batch Loss= 2334.0117, Training Accuracy= 0.836\n",
            "Step 60, batch Loss= 3988.5864, Training Accuracy= 0.805\n",
            "Step 70, batch Loss= 4373.7988, Training Accuracy= 0.758\n",
            "Step 80, batch Loss= 3984.5835, Training Accuracy= 0.812\n",
            "Step 90, batch Loss= 1424.6488, Training Accuracy= 0.883\n",
            "Step 100, batch Loss= 2473.2803, Training Accuracy= 0.844\n",
            "Step 110, batch Loss= 2358.7480, Training Accuracy= 0.852\n",
            "Step 120, batch Loss= 1220.6567, Training Accuracy= 0.883\n",
            "Step 130, batch Loss= 1414.3293, Training Accuracy= 0.922\n",
            "Step 140, batch Loss= 1143.6433, Training Accuracy= 0.898\n",
            "Step 150, batch Loss= 2222.1631, Training Accuracy= 0.867\n",
            "Step 160, batch Loss= 963.7920, Training Accuracy= 0.930\n",
            "Step 170, batch Loss= 796.1940, Training Accuracy= 0.953\n",
            "Step 180, batch Loss= 1662.8580, Training Accuracy= 0.914\n",
            "Step 190, batch Loss= 1072.9835, Training Accuracy= 0.930\n",
            "Step 200, batch Loss= 1513.7463, Training Accuracy= 0.875\n",
            "Step 210, batch Loss= 1059.7482, Training Accuracy= 0.930\n",
            "Step 220, batch Loss= 1055.4928, Training Accuracy= 0.891\n",
            "Step 230, batch Loss= 1002.7559, Training Accuracy= 0.930\n",
            "Step 240, batch Loss= 484.3864, Training Accuracy= 0.938\n",
            "Step 250, batch Loss= 889.8317, Training Accuracy= 0.922\n",
            "Step 260, batch Loss= 828.3765, Training Accuracy= 0.938\n",
            "Step 270, batch Loss= 1039.3650, Training Accuracy= 0.906\n",
            "Step 280, batch Loss= 965.2272, Training Accuracy= 0.914\n",
            "Step 290, batch Loss= 218.3895, Training Accuracy= 0.945\n",
            "Step 300, batch Loss= 822.6775, Training Accuracy= 0.898\n",
            "Step 310, batch Loss= 1595.4052, Training Accuracy= 0.898\n",
            "Step 320, batch Loss= 1376.0951, Training Accuracy= 0.914\n",
            "Step 330, batch Loss= 797.4479, Training Accuracy= 0.969\n",
            "Step 340, batch Loss= 1066.2850, Training Accuracy= 0.938\n",
            "Step 350, batch Loss= 354.6900, Training Accuracy= 0.938\n",
            "Step 360, batch Loss= 811.0348, Training Accuracy= 0.930\n",
            "Step 370, batch Loss= 344.3454, Training Accuracy= 0.953\n",
            "Step 380, batch Loss= 304.9207, Training Accuracy= 0.953\n",
            "Step 390, batch Loss= 1641.7285, Training Accuracy= 0.930\n",
            "Step 400, batch Loss= 318.6302, Training Accuracy= 0.977\n",
            "Step 410, batch Loss= 838.9484, Training Accuracy= 0.922\n",
            "Step 420, batch Loss= 1733.2327, Training Accuracy= 0.922\n",
            "Step 430, batch Loss= 669.9211, Training Accuracy= 0.953\n",
            "Step 440, batch Loss= 469.0701, Training Accuracy= 0.953\n",
            "Step 450, batch Loss= 813.1140, Training Accuracy= 0.930\n",
            "Step 460, batch Loss= 335.6234, Training Accuracy= 0.961\n",
            "Step 470, batch Loss= 630.9474, Training Accuracy= 0.922\n",
            "Step 480, batch Loss= 626.6595, Training Accuracy= 0.914\n",
            "Step 490, batch Loss= 930.4980, Training Accuracy= 0.953\n",
            "Step 500, batch Loss= 594.0399, Training Accuracy= 0.945\n",
            "Step 510, batch Loss= 829.4431, Training Accuracy= 0.930\n",
            "Step 520, batch Loss= 753.3778, Training Accuracy= 0.930\n",
            "Step 530, batch Loss= 168.0503, Training Accuracy= 0.977\n",
            "Step 540, batch Loss= 277.4969, Training Accuracy= 0.969\n",
            "Step 550, batch Loss= 657.3104, Training Accuracy= 0.945\n",
            "Step 560, batch Loss= 233.4672, Training Accuracy= 0.969\n",
            "Step 570, batch Loss= 1017.7163, Training Accuracy= 0.914\n",
            "Step 580, batch Loss= 234.7111, Training Accuracy= 0.953\n",
            "Step 590, batch Loss= 164.7910, Training Accuracy= 0.969\n",
            "Step 600, batch Loss= 236.7528, Training Accuracy= 0.977\n",
            "Step 610, batch Loss= 655.5728, Training Accuracy= 0.953\n",
            "Step 620, batch Loss= 527.1575, Training Accuracy= 0.953\n",
            "Step 630, batch Loss= 332.6820, Training Accuracy= 0.945\n",
            "Step 640, batch Loss= 434.1695, Training Accuracy= 0.961\n",
            "Step 650, batch Loss= 200.2981, Training Accuracy= 0.961\n",
            "Step 660, batch Loss= 1207.1179, Training Accuracy= 0.922\n",
            "Step 670, batch Loss= 244.9174, Training Accuracy= 0.984\n",
            "Step 680, batch Loss= 399.2812, Training Accuracy= 0.961\n",
            "Step 690, batch Loss= 294.0333, Training Accuracy= 0.969\n",
            "Step 700, batch Loss= 393.2536, Training Accuracy= 0.969\n",
            "Step 710, batch Loss= 497.8534, Training Accuracy= 0.992\n",
            "Step 720, batch Loss= 572.4501, Training Accuracy= 0.945\n",
            "Step 730, batch Loss= 461.3218, Training Accuracy= 0.953\n",
            "Step 740, batch Loss= 339.1207, Training Accuracy= 0.953\n",
            "Step 750, batch Loss= 43.2048, Training Accuracy= 0.961\n",
            "Step 760, batch Loss= 386.0820, Training Accuracy= 0.953\n",
            "Step 770, batch Loss= 174.9655, Training Accuracy= 0.984\n",
            "Step 780, batch Loss= 413.1437, Training Accuracy= 0.977\n",
            "Step 790, batch Loss= 176.9491, Training Accuracy= 0.953\n",
            "Step 800, batch Loss= 673.6639, Training Accuracy= 0.945\n",
            "Step 810, batch Loss= 63.2516, Training Accuracy= 0.984\n",
            "Step 820, batch Loss= 139.8986, Training Accuracy= 0.969\n",
            "Step 830, batch Loss= 300.7427, Training Accuracy= 0.953\n",
            "Step 840, batch Loss= 262.7450, Training Accuracy= 0.961\n",
            "Step 850, batch Loss= 313.9360, Training Accuracy= 0.977\n",
            "Step 860, batch Loss= 255.8035, Training Accuracy= 0.969\n",
            "Step 870, batch Loss= 424.7305, Training Accuracy= 0.977\n",
            "Step 880, batch Loss= 42.9531, Training Accuracy= 0.992\n",
            "Step 890, batch Loss= 654.4887, Training Accuracy= 0.961\n",
            "Step 900, batch Loss= 357.5171, Training Accuracy= 0.961\n",
            "Step 910, batch Loss= 56.1585, Training Accuracy= 0.984\n",
            "Step 920, batch Loss= 222.7599, Training Accuracy= 0.977\n",
            "Step 930, batch Loss= 259.2253, Training Accuracy= 0.969\n",
            "Step 940, batch Loss= 546.1498, Training Accuracy= 0.969\n",
            "Step 950, batch Loss= 117.9716, Training Accuracy= 0.984\n",
            "Step 960, batch Loss= 830.5770, Training Accuracy= 0.938\n",
            "Step 970, batch Loss= 312.0220, Training Accuracy= 0.969\n",
            "Step 980, batch Loss= 264.0642, Training Accuracy= 0.969\n",
            "Step 990, batch Loss= 487.6996, Training Accuracy= 0.953\n",
            "Step 1000, batch Loss= 21.1508, Training Accuracy= 0.992\n",
            "최적화 완료\n",
            "Testing Accuracy: 0.98046875\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "eeeDzXaBDvNT",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 89
        },
        "outputId": "9cf90850-e27f-4033-a512-f6a609a32650"
      },
      "cell_type": "code",
      "source": [
        "from __future__ import division, print_function, absolute_import\n",
        "\n",
        "# Import MNIST data\n",
        "from tensorflow.examples.tutorials.mnist import input_data\n",
        "mnist = input_data.read_data_sets(\"/tmp/data/\", one_hot=False)\n",
        "\n",
        "import tensorflow as tf\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Extracting /tmp/data/train-images-idx3-ubyte.gz\n",
            "Extracting /tmp/data/train-labels-idx1-ubyte.gz\n",
            "Extracting /tmp/data/t10k-images-idx3-ubyte.gz\n",
            "Extracting /tmp/data/t10k-labels-idx1-ubyte.gz\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "2K7C_6ECDvQk",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# Training Parameters\n",
        "learning_rate = 0.001\n",
        "num_steps = 3000\n",
        "batch_size = 128\n",
        "\n",
        "# Network Parameters\n",
        "num_input = 784 # MNIST data input (img shape: 28*28)\n",
        "num_classes = 10 # MNIST total classes (0-9 digits)\n",
        "dropout = 0.25 # Dropout, probability to drop a unit"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "al4PtbWMDvTB",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "def conv_net( x_dict , n_classes , dropout , reuse , is_training ) :\n",
        "    \n",
        "    with tf.variable_scope( \"Convnet\" , reuse = reuse ) :\n",
        "        x = x_dict[\"images\"]\n",
        "        \n",
        "        x= tf.reshape( x , shape = [-1 ,28 , 28 , 1 ])\n",
        "        \n",
        "        conv1 = tf.layers.conv2d( x, 32 , 5 ,activation= tf.nn.relu )\n",
        "        conv1 = tf.layers.max_pooling2d( conv1 , 2, 2 )\n",
        "        \n",
        "        conv2 = tf.layers.conv2d( conv1 , 64 , 5, activation = tf.nn.relu)\n",
        "        conv2 = tf.layers.max_pooling2d( conv2 , 2, 2 )\n",
        "        \n",
        "        fc1 = tf.contrib.layers.flatten( conv2 )\n",
        "        fc1 = tf.layers.dense( fc1 , 1024 )\n",
        "        fc1 = tf.layers.dropout( fc1 , rate= dropout , training = is_training ) \n",
        "        \n",
        "        out = tf.layers.dense( fc1 , n_classes )\n",
        "       \n",
        "    return out\n",
        "        "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "0Si81T51DvWK",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# Define the model function (following TF Estimator Template)\n",
        "def model_fn(features, labels, mode):\n",
        "    \n",
        "    # Build the neural network\n",
        "    # Because Dropout have different behavior at training and prediction time, we\n",
        "    # need to create 2 distinct computation graphs that still share the same weights.\n",
        "    logits_train = conv_net(features, num_classes, dropout, reuse=False, is_training=True)\n",
        "    logits_test = conv_net(features, num_classes, dropout, reuse=True, is_training=False)\n",
        "    \n",
        "    # Predictions\n",
        "    pred_classes = tf.argmax(logits_test, axis=1)\n",
        "    pred_probas = tf.nn.softmax(logits_test)\n",
        "    \n",
        "    # If prediction mode, early return\n",
        "    if mode == tf.estimator.ModeKeys.PREDICT:\n",
        "        return tf.estimator.EstimatorSpec(mode, predictions=pred_classes) \n",
        "        \n",
        "    # Define loss and optimizer\n",
        "    loss_op = tf.reduce_mean(tf.nn.sparse_softmax_cross_entropy_with_logits(\n",
        "        logits=logits_train, labels=tf.cast(labels, dtype=tf.int32)))\n",
        "    optimizer = tf.train.AdamOptimizer(learning_rate=learning_rate)\n",
        "    train_op = optimizer.minimize(loss_op, global_step=tf.train.get_global_step())\n",
        "    \n",
        "    # Evaluate the accuracy of the model\n",
        "    acc_op = tf.metrics.accuracy(labels=labels, predictions=pred_classes)\n",
        "    \n",
        "    # TF Estimators requires to return a EstimatorSpec, that specify\n",
        "    # the different ops for training, evaluating, ...\n",
        "    estim_specs = tf.estimator.EstimatorSpec(\n",
        "      mode=mode,\n",
        "      predictions=pred_classes,\n",
        "      loss=loss_op,\n",
        "      train_op=train_op,\n",
        "      eval_metric_ops={'accuracy': acc_op})\n",
        "\n",
        "    return estim_specs"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "FSMjj0GZK-sa",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 91
        },
        "outputId": "039948cf-a55a-4b7e-e195-c5ec1515b185"
      },
      "cell_type": "code",
      "source": [
        "model = tf.estimator.Estimator(model_fn)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Using default config.\n",
            "WARNING:tensorflow:Using temporary folder as model directory: /tmp/tmpnaxxuksc\n",
            "INFO:tensorflow:Using config: {'_model_dir': '/tmp/tmpnaxxuksc', '_tf_random_seed': None, '_save_summary_steps': 100, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': None, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 100, '_train_distribute': None, '_device_fn': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x7fa79b838b00>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "ZuArCQ4gLBB6",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1277
        },
        "outputId": "9aebee7b-5705-45b8-d992-432146de10ce"
      },
      "cell_type": "code",
      "source": [
        "input_fn = tf.estimator.inputs.numpy_input_fn(\n",
        "    x={'images': mnist.train.images}, y=mnist.train.labels,\n",
        "    batch_size=batch_size, num_epochs=None, shuffle=True)\n",
        "# Train the Model\n",
        "model.train(input_fn, steps=num_steps)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Calling model_fn.\n",
            "INFO:tensorflow:Done calling model_fn.\n",
            "INFO:tensorflow:Create CheckpointSaverHook.\n",
            "INFO:tensorflow:Graph was finalized.\n",
            "INFO:tensorflow:Restoring parameters from /tmp/tmpnaxxuksc/model.ckpt-2000\n",
            "INFO:tensorflow:Running local_init_op.\n",
            "INFO:tensorflow:Done running local_init_op.\n",
            "INFO:tensorflow:Saving checkpoints for 2000 into /tmp/tmpnaxxuksc/model.ckpt.\n",
            "INFO:tensorflow:loss = 0.01786662, step = 2000\n",
            "INFO:tensorflow:global_step/sec: 95.1443\n",
            "INFO:tensorflow:loss = 0.009625992, step = 2100 (1.056 sec)\n",
            "INFO:tensorflow:global_step/sec: 114.111\n",
            "INFO:tensorflow:loss = 0.0012876425, step = 2200 (0.878 sec)\n",
            "INFO:tensorflow:global_step/sec: 124.04\n",
            "INFO:tensorflow:loss = 0.0028572963, step = 2300 (0.804 sec)\n",
            "INFO:tensorflow:global_step/sec: 119.343\n",
            "INFO:tensorflow:loss = 0.00773081, step = 2400 (0.839 sec)\n",
            "INFO:tensorflow:global_step/sec: 117.955\n",
            "INFO:tensorflow:loss = 0.010796163, step = 2500 (0.844 sec)\n",
            "INFO:tensorflow:global_step/sec: 118.249\n",
            "INFO:tensorflow:loss = 0.0045140404, step = 2600 (0.847 sec)\n",
            "INFO:tensorflow:global_step/sec: 120.81\n",
            "INFO:tensorflow:loss = 0.000756195, step = 2700 (0.827 sec)\n",
            "INFO:tensorflow:global_step/sec: 121.267\n",
            "INFO:tensorflow:loss = 0.0020728295, step = 2800 (0.825 sec)\n",
            "INFO:tensorflow:global_step/sec: 120.757\n",
            "INFO:tensorflow:loss = 0.0030431934, step = 2900 (0.830 sec)\n",
            "INFO:tensorflow:global_step/sec: 119.778\n",
            "INFO:tensorflow:loss = 0.00061530614, step = 3000 (0.836 sec)\n",
            "INFO:tensorflow:global_step/sec: 118.499\n",
            "INFO:tensorflow:loss = 0.014607573, step = 3100 (0.840 sec)\n",
            "INFO:tensorflow:global_step/sec: 127.466\n",
            "INFO:tensorflow:loss = 0.002639883, step = 3200 (0.784 sec)\n",
            "INFO:tensorflow:global_step/sec: 128.013\n",
            "INFO:tensorflow:loss = 0.0075149853, step = 3300 (0.784 sec)\n",
            "INFO:tensorflow:global_step/sec: 127.044\n",
            "INFO:tensorflow:loss = 0.001943936, step = 3400 (0.788 sec)\n",
            "INFO:tensorflow:global_step/sec: 122.029\n",
            "INFO:tensorflow:loss = 0.016363837, step = 3500 (0.821 sec)\n",
            "INFO:tensorflow:global_step/sec: 124.629\n",
            "INFO:tensorflow:loss = 0.007015534, step = 3600 (0.802 sec)\n",
            "INFO:tensorflow:global_step/sec: 126.333\n",
            "INFO:tensorflow:loss = 0.043827083, step = 3700 (0.793 sec)\n",
            "INFO:tensorflow:global_step/sec: 126.977\n",
            "INFO:tensorflow:loss = 0.0035441888, step = 3800 (0.784 sec)\n",
            "INFO:tensorflow:global_step/sec: 125.351\n",
            "INFO:tensorflow:loss = 0.009347245, step = 3900 (0.801 sec)\n",
            "INFO:tensorflow:global_step/sec: 124.576\n",
            "INFO:tensorflow:loss = 0.00030056073, step = 4000 (0.804 sec)\n",
            "INFO:tensorflow:global_step/sec: 127.475\n",
            "INFO:tensorflow:loss = 0.00029285077, step = 4100 (0.784 sec)\n",
            "INFO:tensorflow:global_step/sec: 124.283\n",
            "INFO:tensorflow:loss = 0.0008301637, step = 4200 (0.805 sec)\n",
            "INFO:tensorflow:global_step/sec: 124.707\n",
            "INFO:tensorflow:loss = 0.00028826317, step = 4300 (0.799 sec)\n",
            "INFO:tensorflow:global_step/sec: 125.137\n",
            "INFO:tensorflow:loss = 0.00010139636, step = 4400 (0.797 sec)\n",
            "INFO:tensorflow:global_step/sec: 125.124\n",
            "INFO:tensorflow:loss = 0.02847623, step = 4500 (0.802 sec)\n",
            "INFO:tensorflow:global_step/sec: 125.547\n",
            "INFO:tensorflow:loss = 0.01579037, step = 4600 (0.796 sec)\n",
            "INFO:tensorflow:global_step/sec: 124.582\n",
            "INFO:tensorflow:loss = 0.00031183244, step = 4700 (0.804 sec)\n",
            "INFO:tensorflow:global_step/sec: 124.966\n",
            "INFO:tensorflow:loss = 0.009960629, step = 4800 (0.798 sec)\n",
            "INFO:tensorflow:global_step/sec: 125.314\n",
            "INFO:tensorflow:loss = 0.00079640676, step = 4900 (0.800 sec)\n",
            "INFO:tensorflow:Saving checkpoints for 5000 into /tmp/tmpnaxxuksc/model.ckpt.\n",
            "INFO:tensorflow:Loss for final step: 0.00017885318.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tensorflow.python.estimator.estimator.Estimator at 0x7fa79b838f28>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 34
        }
      ]
    },
    {
      "metadata": {
        "id": "YJIuRKwOLXZr",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 235
        },
        "outputId": "2644a5e8-f20e-42be-cdd0-a7976b5e6b55"
      },
      "cell_type": "code",
      "source": [
        "input_fn = tf.estimator.inputs.numpy_input_fn(\n",
        "    x={'images': mnist.test.images}, y=mnist.test.labels,\n",
        "    batch_size=batch_size, shuffle=False)\n",
        "# Use the Estimator 'evaluate' method\n",
        "model.evaluate(input_fn)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Calling model_fn.\n",
            "INFO:tensorflow:Done calling model_fn.\n",
            "INFO:tensorflow:Starting evaluation at 2018-09-16-11:40:31\n",
            "INFO:tensorflow:Graph was finalized.\n",
            "INFO:tensorflow:Restoring parameters from /tmp/tmpnaxxuksc/model.ckpt-5000\n",
            "INFO:tensorflow:Running local_init_op.\n",
            "INFO:tensorflow:Done running local_init_op.\n",
            "INFO:tensorflow:Finished evaluation at 2018-09-16-11:40:31\n",
            "INFO:tensorflow:Saving dict for global step 5000: accuracy = 0.9895, global_step = 5000, loss = 0.051539198\n",
            "INFO:tensorflow:Saving 'checkpoint_path' summary for global step 5000: /tmp/tmpnaxxuksc/model.ckpt-5000\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'accuracy': 0.9895, 'global_step': 5000, 'loss': 0.051539198}"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 35
        }
      ]
    },
    {
      "metadata": {
        "id": "fzy7eaVPLrPp",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 143
        },
        "outputId": "3fa642aa-ca03-4884-99db-457c1e888fc9"
      },
      "cell_type": "code",
      "source": [
        "# Predict single images\n",
        "n_images = 4\n",
        "# Get images from test set\n",
        "test_images = mnist.test.images[:n_images]\n",
        "# Prepare the input data\n",
        "input_fn = tf.estimator.inputs.numpy_input_fn(\n",
        "    x={'images': test_images}, shuffle=False)\n",
        "# Use the model to predict the images class\n",
        "preds = list(model.predict(input_fn))\n",
        "\n"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Calling model_fn.\n",
            "INFO:tensorflow:Done calling model_fn.\n",
            "INFO:tensorflow:Graph was finalized.\n",
            "INFO:tensorflow:Restoring parameters from /tmp/tmpnaxxuksc/model.ckpt-5000\n",
            "INFO:tensorflow:Running local_init_op.\n",
            "INFO:tensorflow:Done running local_init_op.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[7, 2, 1, 0]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 36
        }
      ]
    },
    {
      "metadata": {
        "id": "8q4gImBlLx8i",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1427
        },
        "outputId": "6d1c71c9-364b-48e0-c5c3-7ee668d1e586"
      },
      "cell_type": "code",
      "source": [
        "# Display\n",
        "print(n_images )\n",
        "for i in range(n_images):\n",
        "    plt.imshow(np.reshape(test_images[i], [28, 28]), cmap='gray')\n",
        "    plt.show()\n",
        "    print(\"Model prediction:\", preds[i])"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "4\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAUsAAAFKCAYAAACU6307AAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nTkSuQmCC\n",
            "text/plain": [
              "<matplotlib.figure.Figure at 0x7fa79b6a4390>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "Model prediction: 7\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAUsAAAFKCAYAAACU6307AAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n",
            "text/plain": [
              "<matplotlib.figure.Figure at 0x7fa7c7b1c2e8>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "Model prediction: 2\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAUsAAAFKCAYAAACU6307AAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nRK5CYII=\n",
            "text/plain": [
              "<matplotlib.figure.Figure at 0x7fa7e0ab14e0>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "Model prediction: 1\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAUsAAAFKCAYAAACU6307AAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nQmCC\n",
            "text/plain": [
              "<matplotlib.figure.Figure at 0x7fa7e0a5ceb8>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "Model prediction: 0\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}